service:
  name: agent-runner
  port: 8082
  workers: 4

redis:
  host: localhost
  port: 6379
  db: 0
  # Redis Streams configuration (new architecture)
  stream: wf.tasks.agent
  consumer_group: agent_workers
  # Legacy queue names (backward compatibility)
  job_queue: agent:jobs
  result_queue_prefix: agent:results
  timeout: 5

llm:
  provider: openai
  model: gpt-4o
  temperature: 0.1
  max_tokens: 4000
  timeout_sec: 30

orchestrator:
  api_url: http://localhost:8081

storage:
  max_inline_bytes: 10485760  # 10MB
  cas_enabled: true
  s3_enabled: false
