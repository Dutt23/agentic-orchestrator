# Vision Architecture (Production Target)

> **Event-driven orchestration with agentic overlays and full observability**

## ğŸ“– Document Overview

**Purpose:** Complete production architecture with Kafka, WASM, and advanced scaling

**In this document:**
- [System Architecture](#system-architecture) - Complete production diagram
- [Core Principles](#core-architectural-principles) - Event sourcing, overlays, scalability
- [Key Differences](#key-differences-from-phase-1-mvp) - MVP vs. Production comparison
- [Advanced Components](#advanced-components-not-in-phase-1) - WASM optimizer, Kafka, etc.
- [Agent Execution Environments](#agent-execution-environments) - K8s, Lambda, customer infra
- [Data Flow](#data-flow-end-to-end) - Complete request lifecycle
- [Performance Targets](#performance-targets) - 10K workflows/sec goal
- [Core Innovation Explained](#core-innovation-how-agent-resolution-works) - Deep dive on patching

---

## Overview

This document describes the complete production architecture. While Phase 1 (MVP) proves the core concepts with Redis, this vision represents a horizontally scalable, enterprise-grade platform capable of 10K+ workflows/sec with Kafka and WASM optimization.

**Source:** [../references/arch.txt](../references/arch.txt) - Complete vision specification

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Agentic Orchestration Platform (Production)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONTROL PLANE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                                        â”‚       â”‚
â”‚  â”‚  Edge Proxy (HAProxy/Envoy)                          â”‚       â”‚
â”‚  â”‚  â”œâ”€ TLS termination                                  â”‚       â”‚
â”‚  â”‚  â”œâ”€ Rate limiting (workflow-aware)                   â”‚       â”‚
â”‚  â”‚  â”œâ”€ SSE/WS upgrade                                   â”‚       â”‚
â”‚  â”‚  â””â”€ Sticky routing by run_id                        â”‚       â”‚
â”‚  â”‚          â†“                                            â”‚       â”‚
â”‚  â”‚  API Service                                          â”‚       â”‚
â”‚  â”‚  â”œâ”€ Start/Cancel/Replay runs                        â”‚       â”‚
â”‚  â”‚  â”œâ”€ Approve/Reject HITL                             â”‚       â”‚
â”‚  â”‚  â””â”€ ApplyPatch, GetRun/Timeline                     â”‚       â”‚
â”‚  â”‚          â†“                                            â”‚       â”‚
â”‚  â”‚  Orchestrator                                         â”‚       â”‚
â”‚  â”‚  â”œâ”€ Workflow resolution (base + patches)            â”‚       â”‚
â”‚  â”‚  â”œâ”€ Materialization (overlays)                      â”‚       â”‚
â”‚  â”‚  â”œâ”€ Durable timers                                   â”‚       â”‚
â”‚  â”‚  â””â”€ Outbox â†’ Kafka                                   â”‚       â”‚
â”‚  â”‚          â†“                                            â”‚       â”‚
â”‚  â”‚  Validator                                            â”‚       â”‚
â”‚  â”‚  â”œâ”€ Validates agent patches                         â”‚       â”‚
â”‚  â”‚  â”œâ”€ Schema validation                               â”‚       â”‚
â”‚  â”‚  â”œâ”€ Agent spawn limit checks                        â”‚       â”‚
â”‚  â”‚  â””â”€ SSRF protection                                  â”‚       â”‚
â”‚  â”‚                                                        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA PLANE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚  Runner (Go)                                         â”‚        â”‚
â”‚  â”‚  â”œâ”€ Execute function/map/join/composite             â”‚        â”‚
â”‚  â”‚  â”œâ”€ Idempotency keys                                â”‚        â”‚
â”‚  â”‚  â””â”€ CAS I/O                                         â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚  Agent Runner (Any Execution Env)                   â”‚        â”‚
â”‚  â”‚  â”œâ”€ K8s Jobs, Lambda, or customer env              â”‚        â”‚
â”‚  â”‚  â”œâ”€ LLM/tool execution                              â”‚        â”‚
â”‚  â”‚  â”œâ”€ Structured outputs                              â”‚        â”‚
â”‚  â”‚  â””â”€ AIR patch proposals                             â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚  Fanout                                              â”‚        â”‚
â”‚  â”‚  â”œâ”€ Timeline/logs/events streaming                  â”‚        â”‚
â”‚  â”‚  â”œâ”€ SSE/WS for real-time UI                        â”‚        â”‚
â”‚  â”‚  â”œâ”€ Bounded buffers + heartbeats                   â”‚        â”‚
â”‚  â”‚  â””â”€ Multi-user support                              â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚  HITL Service                                        â”‚        â”‚
â”‚  â”‚  â”œâ”€ Human approval gates                            â”‚        â”‚
â”‚  â”‚  â”œâ”€ Timeout + escalation                            â”‚        â”‚
â”‚  â”‚  â””â”€ Branching (approve/reject paths)               â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â”‚  Optimizer (WASM)                                    â”‚        â”‚
â”‚  â”‚  â”œâ”€ Graph rewrite passes                           â”‚        â”‚
â”‚  â”‚  â”œâ”€ HTTP fusion, pruning, caching                  â”‚        â”‚
â”‚  â”‚  â””â”€ Emits OptimizedPatch overlays                  â”‚        â”‚
â”‚  â”‚                                                       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ STORAGE LAYER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚                                                      â”‚         â”‚
â”‚  â”‚  Kafka/Redpanda (Event Bus + Queues)               â”‚         â”‚
â”‚  â”‚  â”œâ”€ workflow.events (domain events)                â”‚         â”‚
â”‚  â”‚  â”œâ”€ node.jobs.{high|medium|low} (work by priority) â”‚         â”‚
â”‚  â”‚  â””â”€ node.results (executor outputs)                â”‚         â”‚
â”‚  â”‚                                                      â”‚         â”‚
â”‚  â”‚  Postgres (Metadata + Event Log)                   â”‚         â”‚
â”‚  â”‚  â”œâ”€ runs (workflow instances)                      â”‚         â”‚
â”‚  â”‚  â”œâ”€ patches (agent modifications)                  â”‚         â”‚
â”‚  â”‚  â”œâ”€ artifacts (workflow versions)                  â”‚         â”‚
â”‚  â”‚  â””â”€ event_log (append-only audit)                  â”‚         â”‚
â”‚  â”‚                                                      â”‚         â”‚
â”‚  â”‚  S3/MinIO (CAS - Content-Addressed Storage)        â”‚         â”‚
â”‚  â”‚  â”œâ”€ All data content-addressed (sha256)            â”‚         â”‚
â”‚  â”‚  â”œâ”€ Workflow definitions                            â”‚         â”‚
â”‚  â”‚  â”œâ”€ Node outputs                                    â”‚         â”‚
â”‚  â”‚  â””â”€ Immutable, deduplicated                        â”‚         â”‚
â”‚  â”‚                                                      â”‚         â”‚
â”‚  â”‚  Dragonfly/Redis (Cache)                           â”‚         â”‚
â”‚  â”‚  â”œâ”€ Memoized node results                          â”‚         â”‚
â”‚  â”‚  â”œâ”€ Session state                                   â”‚         â”‚
â”‚  â”‚  â””â”€ Metadata + CAS pointers                        â”‚         â”‚
â”‚  â”‚                                                      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Architectural Principles

### 1. Deterministic Event Sourcing

**Principle:** Everything is append-only, no mutation

```
Write: Orchestrator â†’ Postgres (event log) â†’ Outbox â†’ Kafka
Execute: Workers consume from Kafka â†’ Store outputs in CAS â†’ Publish results
```

**Benefits:**
- Full audit trail
- Replay from any state
- Conflict resolution via event comparison
- Deterministic reproduction

### 2. Agentic Overlays (Not Mutations!)

**Principle:** Agents propose patches, never mutate base graph

```
Base Workflow (v1.0)
  + Agent Patch 1 (adds nodes)
  + Agent Patch 2 (adds edges)
  + Optimizer Patch (fuses nodes)
  = Materialized Workflow (v1.3)
```

**This is the core innovation!**

**Benefits:**
- Reproducibility (base + patches = deterministic)
- Rollback (remove patch)
- Audit trail (who changed what)
- A/B testing (apply different patch sets)

### 3. Horizontal Scalability via Partitioning

**Partition by run_id:**
```
Kafka partitions (64-256)
  â”œâ”€ run_001 â†’ partition 0
  â”œâ”€ run_002 â†’ partition 1
  â””â”€ run_003 â†’ partition 0

Workers consume from partitions
â†’ Multiple workers per partition (consumer groups)
â†’ Linear scaling
```

### 4. OS-Level Efficiency

**CPU Pinning:**
```
Control Plane: Cores 0-7  (Orchestrator, API, Validator)
Runner Plane: Cores 8-15  (Runners, Agent Runners)
Fanout Plane: Cores 16-19 (Real-time streaming)
```

**Network Stack:**
```
SO_REUSEPORT: Distribute accepts across threads
HTTP/2: Multiplexing for SSE/WS
GRO/GSO: Packet batching (20-30% CPU reduction)
```

**See:** [../operations/SCALABILITY.md](../operations/SCALABILITY.md) and [../../scripts/systemd/README.md](../../scripts/systemd/README.md)

---

## Key Differences from Phase 1 (MVP)

| Aspect | Phase 1 (MVP) | Vision (Production) |
|--------|--------------|---------------------|
| **Event Bus** | Redis Streams | Kafka/Redpanda (64-256 partitions) |
| **Queuing** | RPUSH/BLPOP | Kafka topics (priority-based) |
| **State** | Redis hot path | Event sourcing + Postgres |
| **Communication** | HTTP REST | gRPC (low latency) |
| **Serialization** | JSON | Protobuf (typed, efficient) |
| **Caching** | Basic Redis | Dragonfly (25x throughput) |
| **Agent Execution** | Local processes | K8s Jobs, Lambda, or customer env |
| **Optimizer** | Rust stubs | WASM (compiled, dynamic) |
| **Streaming** | WebSocket | WebTransport (QUIC-based) |
| **Observability** | Logs + metrics | eBPF uprobes + distributed tracing |
| **CLI** | Basic | Full aob CLI (stream, approve, replay) |
| **Throughput** | ~1K workflows/sec | ~10K workflows/sec |
| **Latency** | 5-10ms/hop | <2ms/hop |

---

## Advanced Components (Not in Phase 1)

### 1. WASM Optimizer

**Purpose:** Runtime graph optimization without code deployment

**Optimization Passes:**

1. **HTTP Coalescing** - Merge sequential HTTP nodes into batch call
2. **Predicate Pushdown** - Move filters closer to data source
3. **Common Subexpression Elimination** - Deduplicate identical subgraphs
4. **Loop-Invariant Code Motion** - Hoist computations out of loops
5. **Dead Path Pruning** - Remove unreachable nodes
6. **Parallel Executor** - Convert sequential to parallel where safe
7. **Semantic Cache** - Identify cacheable subgraphs

**Example:**
```
Before:
  fetch_A â†’ parse_A â†’ fetch_B â†’ parse_B â†’ merge

After (optimized):
  batch_fetch(A, B) â†’ parallel_parse(A, B) â†’ merge
```

**Implementation:**
```rust
// crates/dag-optimizer/src/optimizers/http_coalescer.rs
pub fn coalesce_http_nodes(ir: &mut IR) -> Vec<OptimizedPatch> {
    // Find sequential HTTP nodes with same host
    // Merge into composite HTTP batch node
    // Return patch operations as JSON Patch
}
```

**Benefits:**
- Dynamic optimization (no redeploy)
- Safe (validated patches via same validation as agent patches)
- Observable (optimizer emits audit log)

**Code:** [../../crates/dag-optimizer/](../../crates/dag-optimizer/)

---

### 2. Agent Execution Environments

**Purpose:** Isolated, scalable agent execution - customer brings their own environment

**Supported Environments:**

1. **Kubernetes Jobs** (default)
   ```yaml
   apiVersion: batch/v1
   kind: Job
   metadata:
     name: agent-job-{{ .JobID }}
   spec:
     template:
       spec:
         containers:
         - name: agent
           image: acme/agent-runner:v1.2
           resources:
             limits: {memory: "2Gi", cpu: "1000m"}
   ```

2. **AWS Lambda**
   ```json
   {
     "FunctionName": "agent-runner",
     "Runtime": "python3.11",
     "Handler": "main.handler",
     "Environment": {
       "JOB_ID": "{{.JobID}}",
       "RUN_ID": "{{.RunID}}"
     }
   }
   ```

3. **Customer-Provided Environment**
   ```
   Customer deploys agent runner in their infra:
   - On-prem K8s cluster
   - Cloud Run
   - ECS/Fargate
   - Custom Docker setup

   Requirements:
   - Can consume from Kafka topic: agent.jobs
   - Can publish to Kafka topic: agent.results
   - Has network access to OpenAI/Anthropic APIs
   ```

**Benefits:**
- **Flexibility**: Customer chooses infrastructure
- **Isolation**: Agents run in sandboxed environments
- **Resource limits**: CPU/memory enforcement per environment
- **Scalability**: Environment-specific autoscaling
- **Cost control**: Customer pays for their agent compute

---

### 3. Kafka Event Bus

**Purpose:** Replace Redis Streams with production-grade message bus

**Topics:**

```
workflow.events        â†’ Domain events (run lifecycle)
node.jobs.high        â†’ High-priority work
node.jobs.medium      â†’ Medium-priority work
node.jobs.low         â†’ Low-priority work
node.results          â†’ Execution outputs
```

**Configuration:**

```properties
# Producers
enable.idempotence=true
acks=all
linger.ms=5
compression.type=snappy

# Partitions
num.partitions=64  # Scale linearly

# Consumer groups
group.id=workers
enable.auto.commit=false
```

**Benefits:**
- **10x throughput** vs. Redis Streams
- Durable, replicated
- Priority-based queuing
- Exactly-once semantics

---

### 4. aob CLI Tool

**Purpose:** Developer-friendly command-line interface for workflow management

**Key Commands:**

```bash
# Start workflow
aob run start workflow.json --inputs input.json

# Stream logs in real-time
aob logs stream run_7f3e4a

# Filter logs by node
aob logs stream run_7f3e4a --node enrich

# HITL approvals
aob approve ticket_456 approve --reason "LGTM"
aob approve ticket_789 reject --reason "Need more data"

# Replay from checkpoint
aob replay run_7f3e4a --from parse --mode freeze

# Patch management
aob patch list run_7f3e4a
aob patch show patch_abc123
aob patch approve patch_abc123

# Workflow validation
aob workflow validate workflow.json
aob workflow list
```

**Features:**
- SSE-based log streaming (real-time)
- JSON output for scripting
- Progress indicators and spinners
- Fast (Rust-based)
- Low latency (<10ms startup)

**Documentation:** [../cli/README.md](../cli/README.md), [../cli/COMMANDS.md](../cli/COMMANDS.md)

---

## Data Flow (End-to-End)

### 1. Submit Run

```
User/CLI â†’ API: POST /runs {tag: "main", inputs: {...}}
```

### 2. Resolve & Materialize

```
API â†’ Load base workflow from tag
API â†’ Fetch existing patches for workflow
API â†’ Materialize: base + patches â†’ executable workflow
API â†’ Compile to IR (Intermediate Representation)
API â†’ Store IR in cache (Redis/Dragonfly)
```

**This is where agent resolution happens!**

### 3. Initialize Run

```
API â†’ Postgres: INSERT INTO runs (...)
API â†’ Redis/Kafka: Publish first tokens to entry nodes
API â†’ Response: {run_id, status: "RUNNING"}
```

### 4. Execution (Choreography)

```
Worker â†’ Consume from Kafka (or Redis Stream)
Worker â†’ Load config from CAS
Worker â†’ Execute business logic
Worker â†’ Store output in CAS
Worker â†’ Publish completion signal
Coordinator â†’ Route to next nodes based on DAG
```

### 5. Agent Patch Application

```
Agent Worker â†’ Calls LLM â†’ Generates patch
Agent Worker â†’ POST /runs/{run_id}/patch
Orchestrator â†’ Validates patch
Orchestrator â†’ Applies patch (creates new artifact version)
Orchestrator â†’ Recompiles IR
Orchestrator â†’ Updates cached IR
Coordinator â†’ Loads NEW IR on next completion
Coordinator â†’ Routes to NEW nodes from patched IR
```

**Workflow continues with modified topology!**

### 6. Completion Detection

```
Coordinator â†’ Check counter == 0
Coordinator â†’ Check no pending HITL approvals
Coordinator â†’ Mark run as COMPLETED
Coordinator â†’ Cleanup ephemeral state
```

---

## Performance Targets

### Throughput

| Metric | Target | Notes |
|--------|--------|-------|
| Workflow starts | 10,000/sec | Kafka partition parallelism |
| Node executions | 100,000/sec | Horizontal runner scaling |
| Agent decisions | 1,000/sec | LLM API limits + caching |
| HITL approvals | 500/sec | Human bottleneck |

### Latency

| Operation | P50 | P95 | P99 |
|-----------|-----|-----|-----|
| Kafka publish | <1ms | 2ms | 5ms |
| Node execution (simple) | 5ms | 20ms | 50ms |
| Agent decision (cached LLM) | 200ms | 1s | 5s |
| Coordinator routing | <1ms | 2ms | 5ms |

### Scalability

| Component | Scaling Strategy |
|-----------|------------------|
| API Service | Horizontal (stateless) |
| Orchestrator | Horizontal (partition by run_id) |
| Runner | Horizontal (consumer groups) |
| Agent Runner | Environment-specific autoscaling |
| Fanout | Horizontal (sticky sessions) |
| Kafka | Add brokers + partitions |
| Postgres | Read replicas + sharding |

---

## Deployment Modes

### Fast Path Mode

**Goal:** Maximum throughput, minimal tracing

**Optimizations:**
- Minimal event logging (only critical events)
- No overlay diffs stored (just final state)
- Aggressive caching
- Batch Kafka publishes
- Async metadata updates

**Use Case:** High-volume deterministic workflows

---

### Full Fidelity Mode

**Goal:** Complete observability, audit trail

**Features:**
- Every state change logged
- Overlay diffs preserved (base + each patch)
- Real-time UI updates
- Distributed tracing (span per node)
- Full replay capability

**Use Case:** Regulated workloads, demos, debugging

---

## Core Innovation: How Agent Resolution Works

### Problem Statement

Traditional systems:
- **Static workflows**: Can't modify during execution
- **Dynamic agents**: No deterministic backbone

**Our approach:** Merge both!

### Solution: Materialization + Recompilation

**Step-by-step:**

1. **Base Workflow** (stored in database)
   ```json
   {
     "nodes": [
       {"id": "fetch", "type": "http"},
       {"id": "process", "type": "function"}
     ],
     "edges": [{"from": "fetch", "to": "process"}]
   }
   ```

2. **Agent Decides to Patch** (mid-execution)
   ```python
   llm_response = llm.call("Add email notification")
   patch = {
     "operations": [
       {"op": "add", "path": "/nodes/-", "value": {"id": "email", "type": "task"}},
       {"op": "add", "path": "/edges/-", "value": {"from": "process", "to": "email"}}
     ]
   }
   ```

3. **Validation** (3 layers)
   - Python: Syntax + agent spawn limit
   - Go: Schema validation
   - Coordinator: Security check

4. **Materialization** (base + patches)
   ```json
   {
     "nodes": [
       {"id": "fetch", "type": "http"},
       {"id": "process", "type": "function"},
       {"id": "email", "type": "task"}  â† NEW!
     ],
     "edges": [
       {"from": "fetch", "to": "process"},
       {"from": "process", "to": "email"}  â† NEW!
     ]
   }
   ```

5. **Recompilation to IR**
   ```
   Materialized workflow â†’ IR Compiler â†’ Intermediate Representation
   â†’ Cache in Redis: ir:{run_id}
   ```

6. **Coordinator Picks Up** (on next completion signal)
   ```go
   ir := loadIR(runID)  // Gets NEW version!
   nextNodes := determineNextNodes(ir, completedNode)
   // Routes to "email" node from patched IR
   ```

**This is how we resolve agent intentions into execution!**

---

## Migration Path from Phase 1

**See:** [MIGRATION_PATH.md](./MIGRATION_PATH.md) for detailed evolution strategy.

**Summary:**
1. **Phase 2:** Add Kafka alongside Redis (dual-write)
2. **Phase 3:** Move workers to Kafka (dual-read), verify consistency
3. **Phase 4:** Remove Redis writes (Kafka primary)
4. **Phase 5:** Compile WASM optimizer
5. **Phase 6:** Add gRPC alongside HTTP
6. **Phase 7:** Deploy agent runners in customer environments

**Timeline:** 6-12 months for full migration (incremental, no downtime)

---

## References

**Vision Source:**
- [../references/arch.txt](../references/arch.txt) - Complete vision document
- [../references/readme.MD](../references/readme.MD) - Project README

**Implementation Guides:**
- [../../docs/CHOREOGRAPHY_EXECUTION_DESIGN.md](../../docs/CHOREOGRAPHY_EXECUTION_DESIGN.md) - Execution model
- [../../docs/AGENT_SERVICE.md](../../docs/AGENT_SERVICE.md) - Agent implementation
- [../references/performance-tuning.MD](../references/performance-tuning.MD) - Performance guide

**Operations:**
- [../../scripts/systemd/README.md](../../scripts/systemd/README.md) - OS-level tuning
- [../operations/SCALABILITY.md](../operations/SCALABILITY.md) - Scaling strategies

---

**Status:** Fully designed, architecture validated through Phase 1 implementation, ready for incremental evolution.
